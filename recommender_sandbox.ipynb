{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from upstash_redis import Redis\n",
    "from apscheduler.schedulers.blocking import BlockingScheduler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env.py\")\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# 1️⃣ Database & Redis\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "# Connect to PostgreSQL\n",
    "conn = psycopg2.connect(os.getenv(\"DATABASE_URL\"))\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_by_cosine_similarity(target_vector, comparison_vectors):\n",
    "    \"\"\"\n",
    "    Ranks comparison vectors by their cosine similarity to a target vector.\n",
    "    Outputs the \n",
    "    \n",
    "    Parameters:\n",
    "    target_vector: array-like of shape (1, n_features) --The reference vector for comparison\n",
    "    comparison_vectors: array-like of shape (1:video_id + n_samples, n_features) --The vectors to compare against the target\n",
    "        \n",
    "    Returns:\n",
    "    list of tuples: (index, similarity_score) sorted by similarity in descending order\n",
    "    \"\"\"\n",
    "    # Cast input to arrays for easy manipulation\n",
    "    target_vector = np.array(target_vector).reshape(1, -1) # cast as array with 1 row and any numbrer of columns (-1)\n",
    "    # extract video_id\n",
    "    video_ids = comparison_vectors\n",
    "    comparison_vectors = np.array(comparison_vectors)\n",
    "    \n",
    "    # Calculate cosine similarities\n",
    "    # target_vector: shape (1,768)\n",
    "    # comparison_vector: shape (#videos,768)\n",
    "    # output: shape (1, #videos)\n",
    "    similarities = cosine_similarity(target_vector, comparison_vectors)[0] # one row per row of the target\n",
    "    print(\"similarities\", similarities)\n",
    "\n",
    "    map_video_score = zip(video_ids, similarities)\n",
    "    print(\"map_video_score\", map_video_score)\n",
    "\n",
    "    ranked_similarities = sorted(map_video_score, key = lambda x: x[1], reverse=True)\n",
    "    print(\"ranked_similarities\", ranked_similarities)\n",
    "\n",
    "    return ranked_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity scores for user 4e5ea187-ae0e-42e4-997c-67ddb1b28270: ['0.60', '0.59', '0.46', '0.45', '0.45', '0.45', '0.45', '0.44']\n",
      "Similarity scores for user 6fb5a42d-8116-4e60-81d2-b62210f245b3: ['0.85', '0.74', '0.45', '0.42', '0.41', '0.40', '0.40', '0.39']\n",
      "Similarity scores for user 0c7fda0a-078b-4bcd-a595-21ec1cfe9ea0: ['0.63', '0.62', '0.61', '0.60', '0.59', '0.47', '0.41', '0.40']\n",
      "Similarity scores for user e40cf1de-5ad0-4e2c-8e5e-d35e062064f8: ['0.85', '0.74', '0.45', '0.42', '0.41', '0.40', '0.40', '0.39']\n"
     ]
    }
   ],
   "source": [
    "def get_similarity_scores(target_vector, comparison_vectors):\n",
    "  \"\"\"\n",
    "  gets cosine similarity to a target vector\n",
    "  \n",
    "  Parameters:\n",
    "  user_embedding: array-like of shape (1, n_features) --The reference vector for comparison\n",
    "  videos_embedding: array-like of shape (1:video_id + n_samples, n_features) --The vectors to compare against the target\n",
    "      \n",
    "  Returns:\n",
    "  list of tuples: (video_id, similarity_score)\n",
    "  \"\"\"\n",
    "  # print(\"LOG INPUT 1\", target_vector)\n",
    "  # print(\"LOG INPUT 2\", comparison_vectors)\n",
    "\n",
    "  # Cast input to arrays for easy manipulation\n",
    "  target_vector_json = json.loads(target_vector)\n",
    "  target_vector_arr = np.array(target_vector_json).reshape(1, -1) # cast as array with 1 row and any numbrer of columns (-1)\n",
    "\n",
    "  # extract video_id\n",
    "  video_ids = [comp[0] for comp in comparison_vectors]\n",
    "\n",
    "  # extract videos embeddings\n",
    "  comparison_vectors_json = [json.loads(comp[1]) for comp in comparison_vectors]\n",
    "  comparison_vectors_arr = np.array(comparison_vectors_json)\n",
    "\n",
    "  # Calculate cosine similarities\n",
    "  # target_vector: shape (1,768)\n",
    "  # comparison_vector: shape (#videos,768)\n",
    "  # output: shape (1, #videos)\n",
    "  # The 'X' parameter of cosine_similarity must be an array-like or a sparse matrix.\n",
    "  # parameters must be json objecrts cast into array\n",
    "  similarities = cosine_similarity(target_vector_arr, comparison_vectors_arr)[0] # one row per row of the target\n",
    "  # print(\"similarities\", similarities)\n",
    "\n",
    "  map_video_score = list(zip(video_ids, similarities))\n",
    "\n",
    "  # print(\"ranked_similarities\", ranked_similarities)\n",
    "\n",
    "  return map_video_score\n",
    "\n",
    "# for each user: rank cosine similarity with existing videos --videos.embeddings\n",
    "# for(id in user_ids):\n",
    "map_user_ranked_similarities = {}\n",
    "# user_ids: [(id, embedding)]\n",
    "for user_id, user_embedding in user_ids:\n",
    "    # map video_id to scores\n",
    "    map_video_scores = get_similarity_scores(user_embedding, videos_embedding)\n",
    "    # rank scores\n",
    "    ranked_scores = sorted(map_video_scores, key = lambda x: x[1], reverse=True)\n",
    "    # returned ranked list\n",
    "    map_user_ranked_similarities[user_id] = ranked_scores\n",
    "\n",
    "    print(f\"Similarity scores for user {user_id}: {[f'{tup[1]:.2f}' for tup in map_user_ranked_similarities[user_id]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4513698 , 0.59249111, 0.46373789, 0.43788369, 0.60124828,\n",
       "        0.45461222, 0.44625027, 0.44931188]])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use json.lodas in a stringified json! '[....]'\n",
    "\n",
    "# get users and profile embeddings\n",
    "cursor.execute(\"SELECT id, embeddings FROM users\")\n",
    "user_ids =  cursor.fetchall()\n",
    "\n",
    "# get all video embeddings\n",
    "cursor.execute(\"SELECT id, embeddings FROM videos WHERE embeddings IS NOT NULL\")\n",
    "videos_embedding = cursor.fetchall() # (#videos, #embeddings + 1)\n",
    "\n",
    "# get test user\n",
    "test_user_emb = user_ids[0][1] # stringified json\n",
    "test_user_emb_json = json.loads(test_user_emb)\n",
    "test_user_emb_arr = np.array(test_user_emb_json).reshape(1,-1) # load json and turn into an array\n",
    "\n",
    "# get test video\n",
    "test_videos_ids = [ve[0] for ve in videos_embedding][0]\n",
    "\n",
    "# get test video embedding\n",
    "# test_videos_embs = np.array([json.loads(ve[1]) for ve in videos_embedding]) # Convert to array of embeddings\n",
    "test_videos_embs = [ve[1] for ve in videos_embedding] # [stringified json]\n",
    "test_videos_embs_json = [json.loads(ve[1]) for ve in videos_embedding] # [json]\n",
    "test_videos_embs_arr = np.array(test_videos_embs_json)\n",
    "\n",
    "# The 'X' parameter of cosine_similarity must be an array-like or a sparse matrix.\n",
    "# poarameters must be json objecrts cast into array\n",
    "cosine_similarity(test_user_emb_arr, test_videos_embs_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VEMB 10 [2, 2, 2, 2, 2, 2, 2]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '67dbacfa-6685-45da-96ee-0709e796af63'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[299], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m [json\u001b[38;5;241m.\u001b[39mloads(video[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m video \u001b[38;5;129;01min\u001b[39;00m video_ids \u001b[38;5;28;01mif\u001b[39;00m video[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVEMB\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(video_embeddings), [\u001b[38;5;28mlen\u001b[39m(video_embeddings[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m1\u001b[39m)])\n\u001b[0;32m---> 15\u001b[0m map_user_ranked_similarities[user_id] \u001b[38;5;241m=\u001b[39m \u001b[43mrank_by_cosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecommendations for user \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmap_user_ranked_similarities[user_id]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[296], line 23\u001b[0m, in \u001b[0;36mrank_by_cosine_similarity\u001b[0;34m(target_vector, comparison_vectors)\u001b[0m\n\u001b[1;32m     17\u001b[0m comparison_vectors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(comparison_vectors)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Calculate cosine similarities\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# target_vector: shape (1,768)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# comparison_vector: shape (#videos,768)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# output: shape (1, #videos)\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m similarities \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomparison_vectors\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# one row per row of the target\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarities\u001b[39m\u001b[38;5;124m\"\u001b[39m, similarities)\n\u001b[1;32m     26\u001b[0m map_video_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(video_ids, similarities)\n",
      "File \u001b[0;32m~/Documents/Dev/headstarter/projects/11.tiktok-clone/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Dev/headstarter/projects/11.tiktok-clone/.venv/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:1741\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m \n\u001b[1;32m   1697\u001b[0m \u001b[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1737\u001b[0m \u001b[38;5;124;03m       [0.57..., 0.81...]])\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1739\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[0;32m-> 1741\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m normalize(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "File \u001b[0;32m~/Documents/Dev/headstarter/projects/11.tiktok-clone/.venv/lib/python3.12/site-packages/sklearn/metrics/pairwise.py:209\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, ensure_all_finite, ensure_2d, copy)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m    201\u001b[0m         X,\n\u001b[1;32m    202\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[1;32m    208\u001b[0m     )\n\u001b[0;32m--> 209\u001b[0m     Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m precomputed:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/Documents/Dev/headstarter/projects/11.tiktok-clone/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1055\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1053\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1055\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1058\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m   1059\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Dev/headstarter/projects/11.tiktok-clone/.venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:839\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    837\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 839\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '67dbacfa-6685-45da-96ee-0709e796af63'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# get users and profile embeddings\n",
    "cursor.execute(\"SELECT id, embeddings FROM users\")\n",
    "user_ids =  cursor.fetchall()\n",
    "\n",
    "# for each user: rank cosine similarity with existing videos --videos.embeddings\n",
    "# for(id in user_ids):\n",
    "map_user_ranked_similarities = {}\n",
    "for user_id, embeddings in user_ids:\n",
    "    cursor.execute(\"SELECT id, embeddings FROM videos\")\n",
    "    video_embeddings = cursor.fetchall()\n",
    "    [json.loads(video[1]) for video in video_ids if video[1] is not None]\n",
    "    print(\"VEMB\", len(video_embeddings), [len(video_embeddings[i]) for i in np.arange(1,8,1)])\n",
    "    map_user_ranked_similarities[user_id] = rank_by_cosine_similarity(json.loads(embeddings), video_embeddings)\n",
    "    print(f\"Recommendations for user {user_id}: {map_user_ranked_similarities[user_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4e5ea187-ae0e-42e4-997c-67ddb1b28270': [(4, np.float64(0.601248277626046)),\n",
       "  (1, np.float64(0.5924911087881568)),\n",
       "  (2, np.float64(0.4637378879339542)),\n",
       "  (5, np.float64(0.45461221852408396)),\n",
       "  (0, np.float64(0.4513697983750683)),\n",
       "  (7, np.float64(0.4493118782720349)),\n",
       "  (6, np.float64(0.4462502749271937)),\n",
       "  (3, np.float64(0.4378836914040903))],\n",
       " '6fb5a42d-8116-4e60-81d2-b62210f245b3': [(1, np.float64(0.8466133985740051)),\n",
       "  (4, np.float64(0.7378676681956524)),\n",
       "  (5, np.float64(0.45434188314640883)),\n",
       "  (3, np.float64(0.42354532664698324)),\n",
       "  (2, np.float64(0.4074677863587103)),\n",
       "  (6, np.float64(0.40332055528695165)),\n",
       "  (0, np.float64(0.4011985006337363)),\n",
       "  (7, np.float64(0.3908751415885182))],\n",
       " '0c7fda0a-078b-4bcd-a595-21ec1cfe9ea0': [(0, np.float64(0.6254746761975318)),\n",
       "  (4, np.float64(0.6150461009496336)),\n",
       "  (7, np.float64(0.6061571771667127)),\n",
       "  (1, np.float64(0.5984827914142251)),\n",
       "  (6, np.float64(0.590334801804286)),\n",
       "  (5, np.float64(0.4718988899587716)),\n",
       "  (2, np.float64(0.4085685357466947)),\n",
       "  (3, np.float64(0.4028322350483392))],\n",
       " 'e40cf1de-5ad0-4e2c-8e5e-d35e062064f8': [(1, np.float64(0.8466133985740051)),\n",
       "  (4, np.float64(0.7378676681956524)),\n",
       "  (5, np.float64(0.45434188314640883)),\n",
       "  (3, np.float64(0.42354532664698324)),\n",
       "  (2, np.float64(0.4074677863587103)),\n",
       "  (6, np.float64(0.40332055528695165)),\n",
       "  (0, np.float64(0.4011985006337363)),\n",
       "  (7, np.float64(0.3908751415885182))]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_user_ranked_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
